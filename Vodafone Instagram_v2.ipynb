{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##16/02\n",
    " Firmar o padrão das informações de cada post\n",
    " Fazer o loop pra uma lista de links que eu escolher\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##17/02 Função dentro de uma lista e corrigir e padronizar tudo dentro da coleta info post e coleta comentários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scapping Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import pandas\n",
    "from collections import OrderedDict\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from random import seed\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from time import time       # Other imports\n",
    "from time import sleep\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from random import seed\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd, numpy as np\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bs(session, url):\n",
    "    \"\"\"Makes a GET requests using the given Session object\n",
    "    and returns a BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    r = None\n",
    "    while True:\n",
    "        r = session.get(url)\n",
    "        if r.ok:\n",
    "            break\n",
    "    return BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To block the notifications\n",
    "# options = webdriver.ChromeOptions()\n",
    "# prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "# options.add_experimental_option(\"prefs\",prefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open the web browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created: This version of ChromeDriver only supports Chrome version 87\nCurrent browser version is 89.0.4389.82 with binary path C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-125b57c0b399>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdriver\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/GSantos/Documents/GABRIEL RAVI/Web Scrapping/chromedriver_win32/chromedriver.exe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             RemoteWebDriver.__init__(\n\u001b[0m\u001b[0;32m     77\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                 command_executor=ChromeRemoteConnection(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[0;32m    155\u001b[0m             warnings.warn(\"Please use FirefoxOptions to set browser profile\",\n\u001b[0;32m    156\u001b[0m                           DeprecationWarning, stacklevel=2)\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrowser_profile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_switch_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSwitchTo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mobile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMobile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[1;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[0;32m    250\u001b[0m         parameters = {\"capabilities\": w3c_caps,\n\u001b[0;32m    251\u001b[0m                       \"desiredCapabilities\": capabilities}\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'sessionId'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m: Message: session not created: This version of ChromeDriver only supports Chrome version 87\nCurrent browser version is 89.0.4389.82 with binary path C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\n"
     ]
    }
   ],
   "source": [
    "driver  = webdriver.Chrome(\"C:/Users/GSantos/Documents/GABRIEL RAVI/Web Scrapping/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username='gabrielravisantos'\n",
    "driver.get('https://www.instagram.com/'+username+'/?hl=en')\n",
    "url = 'https://www.instagram.com/' + username\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listagem Empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.instagram.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = pd.read_excel('Lista_Ravi_Insta.xlsx')\n",
    "\n",
    "ig['posts'] = ig['Link']\n",
    "# fb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selenium script to scroll to the bottom, wait 3 seconds for the next batch of data to load, then continue scrolling.  It will continue to do this until the page stops loading new data.\n",
    "# lenOfPage = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "# match=False\n",
    "# while(match==False):\n",
    "#     lastCount = lenOfPage\n",
    "#     sleep(3)\n",
    "#     lenOfPage = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "#     if lastCount==lenOfPage:\n",
    "#         match=True\n",
    "\n",
    "# # Now that the page is fully scrolled, grab the source code.\n",
    "# source_data = driver.page_source\n",
    "\n",
    "# # Throw your source into BeautifulSoup and start parsing!\n",
    "# bs_data = bs(source_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def posts_urls() -> None:\n",
    "#         \"\"\"Taking the URLs from posts and appending in self.links\"\"\"\n",
    "#         elements = driver.find_elements_by_xpath('//a[@href]')\n",
    "#         teste = []\n",
    "#         for elem in elements:\n",
    "#             urls = elem.get_attribute('href')\n",
    "#             teste.append(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_href() -> None:\n",
    "        elements = driver.find_elements_by_xpath('//a[@href]')\n",
    "        for elem in elements:\n",
    "            urls = elem.get_attribute('href')\n",
    "            if 'p' in urls.split('/'):\n",
    "                links.append(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listona = []\n",
    "listona2= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "def scroll_down(driver) -> None:\n",
    "        \"\"\"Scrolling down the page and taking the URLs\"\"\"\n",
    "        global listona\n",
    "        global listona2\n",
    "        listona = []\n",
    "        listona2 = []\n",
    "        post_url = []\n",
    "        last_height = 0\n",
    "        while True:\n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "            sleep(5)\n",
    "            elements = driver.find_elements_by_xpath('//a[@href]')\n",
    "                       \n",
    "            for elem in elements:\n",
    "                urls = elem.get_attribute('href')\n",
    "                listona.append(urls)    \n",
    "                \n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            \n",
    "            listona2 += listona\n",
    "            \n",
    "listona_zord = list(dict.fromkeys(listona2))\n",
    "posts_url = [ x for x in listona_zord if \"https://www.instagram.com/p/\" in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll_down(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listona_zord = list(dict.fromkeys(listona2))\n",
    "posts_url = [ x for x in listona_zord if \"https://www.instagram.com/p/\" in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listona2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(posts_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletando Informações do Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = driver.page_source\n",
    "soup = BeautifulSoup(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_post():\n",
    "    \n",
    "    global texto_post\n",
    "    global data_post\n",
    "    global contagem_reacoes\n",
    "    #global autor_post_id\n",
    "    global tipo_post_video\n",
    "    global tipo_post_photo\n",
    "    global time_post\n",
    "    global time_of_post2\n",
    "    global data_post_real\n",
    "    global data \n",
    "    \n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    ######### DATA POST\n",
    "    data_post = []\n",
    "    \n",
    "    data = driver.find_element_by_tag_name('time')\n",
    "    data_post_real= data.get_attribute(\"datetime\") \n",
    "    \n",
    "    try:\n",
    "        for i in soup.findAll('time'):\n",
    "                if i.has_attr('datetime'):\n",
    "                    data_post.append(i['datetime'])\n",
    "        time_post = data_post[0]\n",
    "    except:\n",
    "        time_post = [\"NaN\"]\n",
    "    \n",
    "   # texto_post2 = []\n",
    "    #time_of_post2 = driver.find_element_by_xpath('//a/time').get_attribute(\"datetime\")\n",
    "    \n",
    "\n",
    "    texto_post = []\n",
    "    try:\n",
    "        for i in driver.find_elements_by_xpath(\"//li/div/div/div/span\"):\n",
    "            texto_post.append(i.text)\n",
    "        texto_post = texto_post[0]    \n",
    "                #Get the first element\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "    if texto_post == []:\n",
    "        texto_post = [\"NaN\"]  \n",
    "        \n",
    "    \n",
    "     ################\n",
    "    try:    \n",
    "        name_pattern = re.compile(r'webelement', flags = re.M)\n",
    "        tipo_post_video = len(name_pattern.findall(str(driver.find_element_by_tag_name('video')))) ##ok\n",
    "    except:\n",
    "        tipo_post_video = [\"0\"] \n",
    "    \n",
    "   # name_pattern = re.compile(r'webelement', flags = re.M)\n",
    "   # tipo_post_photo = len(name_pattern.findall(str(driver.find_element_by_tag_name('img'))))\n",
    "\n",
    "#### Class to multi photos: vi798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pattern = re.compile(r'webelement', flags = re.M)\n",
    "name_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_post_video = len(name_pattern.findall(str(driver.find_element_by_tag_name('video'))))\n",
    "tipo_post_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_post()\n",
    "print(time_post)\n",
    "print(texto_post)\n",
    "print(tipo_post_video)\n",
    "print(data_post_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## FUNCIONA DO LADO DE FORA\n",
    "# name_pattern = re.compile(r'webelement', flags = re.M)\n",
    "# tipo_post_photo = len(name_pattern.findall(str(driver.find_element_by_tag_name('img'))))\n",
    "# #tipo_post_photo\n",
    "\n",
    "# tipo_post_video = len(name_pattern.findall(str(driver.find_element_by_tag_name('video'))))\n",
    "# tipo_post_video\n",
    "\n",
    "\n",
    "# ## Lista de itens pra ver se tem o Video\n",
    "# # Class Ckrof\n",
    "# # Class _9AhH0\n",
    "# #eLAPa RzuR0\n",
    "# # ZyFrc\n",
    "# # tR2pe ##\n",
    "# # rQDP3\n",
    "# # pR7Pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = driver.find_elements_by_xpath(\"//div[@class ='eLAPa kPFhm']\")  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#links = driver.find_elements_by_class_name('ZyFrc')\n",
    "# links = driver.find_elements_by_xpath(\"//div[@class ='rQDP3']\") \n",
    "# len(links) \n",
    "\n",
    "# content = driver.page_source\n",
    "# soup = BeautifulSoup(content)\n",
    "# texto_post = []\n",
    "# #_6lAjh \n",
    "\n",
    "# for texto_post_ in driver.find_elements_by_tag_name('span'):\n",
    "#                 texto_post.append(texto_post_.text)        \n",
    "# texto_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .text.replace('<h3 class=\"_6lAjh\"><div class=\"Igw0E IwRSH eGOV_ _4EzTm ItkAi\"><span class=\"Jv7Aj mArmR MqpiF\"><a class=\"sqdOP yWX7d _8A5w5 ZIAjV\" href=\"/joao.carmo.5283/\" tabindex=\"0\">',\" \").replace(\"\\n\",\" \").strip()\n",
    "#     name1=a.find('span', attrs={'class':''}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletando Informações dos Comentários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisar:\n",
    "- Limpeza da variável \"Likes\"\n",
    "- Status se está pegando todos os comentários "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_comments():\n",
    "\n",
    "    global comments2 #ok\n",
    "    global comment_id2\n",
    "    global autor2 #ok\n",
    "    global like_comentario2\n",
    "    global hora2 #ok\n",
    "    global autor_id2\n",
    "    global n_comments2\n",
    "    #global n_respostas2\n",
    "    global comment_url2\n",
    "    global link_perfil2 \n",
    "    global time_post\n",
    "    global time_of_post\n",
    "            \n",
    "    comentario = driver.find_elements_by_css_selector('.C4VMK span')\n",
    "    autor_comentario = driver.find_elements_by_class_name('_6lAjh')\n",
    "    container = driver.find_elements_by_class_name('C4VMK')\n",
    "    #time_post Está ali embaixo\n",
    "    #likes_post\n",
    "    links = driver.find_elements_by_class_name('_6lAjh ')\n",
    "    \n",
    "    \n",
    "    autor = []\n",
    "    comentarios = []\n",
    "    time = []       \n",
    "    horario_post2 = []\n",
    "    link_perfil= []\n",
    "    \n",
    "    ##AUTOR\n",
    "#     for autor0 in autor_comentario:\n",
    "#         autor.append(autor0.text)\n",
    "    \n",
    "    ##COMENTÁRIO\n",
    "    for i in comentario:\n",
    "        comentarios.append(i.text) \n",
    "    \n",
    "    coments = comentarios[1::2]  \n",
    "   #print(comments)\n",
    "    autor = comentarios[0::2]\n",
    "   #print(autor)\n",
    "    \n",
    "    ##HORA COMENTÁRIO\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    for i in soup.findAll('time'):\n",
    "        if i.has_attr('datetime'):\n",
    "            time.append(i['datetime'])\n",
    "    time_post = time[1:]\n",
    "    \n",
    "    #HORA POST\n",
    "    #horario_post = time[0] ### Colocar depois\n",
    "    \n",
    "    ##LIKES_COMENTÁRIO\n",
    "    containerzaum = []\n",
    "    like_comentario = []\n",
    "    \n",
    "    try:\n",
    "        for i in container:\n",
    "            containerzaum.append(i.text)\n",
    "\n",
    "        containerzaum[0] = \"XX--POST--XX\"\n",
    "        containerzaum\n",
    "\n",
    "        for cont in containerzaum:\n",
    "                like_comentario.append(cont[-12:])\n",
    "    except:\n",
    "            like_comentario = [\"NaN\"]\n",
    "        \n",
    "\n",
    "    \n",
    "    for i in links:\n",
    "        link_perfil.append(i.find_element_by_css_selector('a').get_attribute('href'))    \n",
    "    \n",
    "    time_of_post = driver.find_element_by_xpath('//a/time').get_attribute(\"datetime\")\n",
    "\n",
    "    \n",
    "    autor2 += autor \n",
    "    comments2 += coments\n",
    "    hora2 += time_post\n",
    "    like_comentario2 += like_comentario\n",
    "    link_perfil2 += link_perfil\n",
    "    time_of_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autor2 = []\n",
    "comments2 = []\n",
    "hora2 = []\n",
    "like_comentario2 = []\n",
    "horario_post2 = []\n",
    "link_perfil2 = []\n",
    "\n",
    "\n",
    "scrap_comments()\n",
    "\n",
    "\n",
    "print(autor2) # 3\n",
    "print(comments2)  # 3\n",
    "print(hora2)  # 3\n",
    "print(like_comentario2)  # 3\n",
    "print(len(like_comentario2))\n",
    "#horario_post2 NOT DONE\n",
    "#print(link_perfil2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method1\n",
    "# likes = driver.find_elements_by_xpath(\"//button[@class ='FH9sR']\")\n",
    "# like = []\n",
    "# for i in likes:\n",
    "#         like.append(i.text)\n",
    "# like        \n",
    "\n",
    "# #Method 2\n",
    "# likes_comentario = driver.find_elements_by_class_name('FH9sR')\n",
    "# like =[]\n",
    "# for i in likes_comentario:\n",
    "#         like.append(i.text)\n",
    "# like\n",
    "\n",
    "# #Method 3\n",
    "# likes = []\n",
    "# likes = [i.split('\\n', 1)[1] for i in containerzaum]\n",
    "# likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função dentro de uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "post_data = OrderedDict()\n",
    "\n",
    "post_data['Categoria'] = []\n",
    "post_data['Empresa'] = []\n",
    "post_data['post_author_url'] = []\n",
    "post_data['n'] = []\n",
    "post_data['Empresa'] = []\n",
    "post_data['post_author_url'] = []\n",
    "post_data['n'] = []\n",
    "post_data['URL_Post'] = []\n",
    "post_data['Texto_Post'] = []\n",
    "post_data['Data_Post'] = []\n",
    "post_data['Partilhas'] = []\n",
    "post_data['Tipo_post_video'] = []\n",
    "post_data['Tipo_post_foto'] = []\n",
    "post_data['Tipo_post_evento'] = []\n",
    "post_data['Tipo_post_link'] = []\n",
    "post_data['all'] = []\n",
    "post_data['Likes_Comentario'] = []\n",
    "post_data['Autor'] = []\n",
    "post_data['Autor_id'] = []\n",
    "post_data['Comentario']  = []\n",
    "post_data['Comentario_id'] = []\n",
    "post_data['Data_Comentario'] = []\n",
    "post_data['N_respostas'] = []\n",
    "post_data['Tempo_recolha'] = []\n",
    "#post_data['Autor_Post_ID'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the URL Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link():\n",
    "    elements = driver.find_elements_by_xpath(\"//article/div/div/div/div/a[@href]\")\n",
    "    posts_url = []\n",
    "\n",
    "\n",
    "    for elem in elements:\n",
    "        urls = elem.get_attribute(\"href\")\n",
    "        if \"p\" in urls.split(\"/\"):\n",
    "            posts_url.append(urls)\n",
    "    print(posts_url)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_link()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(posts_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ativar a função "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "profile_bs = BeautifulSoup(page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.instagram.com/p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig[\"posts\"][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantos Links deveria conter\n",
    "elements = driver.find_element_by_class_name('g47SY ')\n",
    "print(\"Deveria ter:\" + elements.text + \" Posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_href():\n",
    "        elements = driver.find_elements_by_xpath('//a[@href]')\n",
    "        for elem in elements:\n",
    "            urls = elem.get_attribute('href')\n",
    "            if 'p' in urls.split('/'):\n",
    "                links.append(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here comes the Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig[\"posts\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f844c07648c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msize_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"posts\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcompany\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlista_posts\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"posts\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    size_ = 0\n",
    "    with tqdm(total=len(ig[\"posts\"][0:])) as pbar:\n",
    "        for company, lista_posts in enumerate(ig[\"posts\"][0:], start=0):\n",
    "            \n",
    "            \n",
    "            pbar.set_description(f'Tamanho da base: {size_} obs')\n",
    "            pbar.update(1)   \n",
    "            \n",
    "            driver.get(lista_posts)\n",
    "        \n",
    "            scroll_down(driver)\n",
    "            listona_zord = list(dict.fromkeys(listona2))\n",
    "            posts_url = [ x for x in listona_zord if \"https://www.instagram.com/p/\" in x ]\n",
    "            \n",
    "            print(len(posts_url))\n",
    "            \n",
    "            page_source = driver.page_source\n",
    "            profile_bs = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "            company_ = ig[\"Empresa\"][company]\n",
    "\n",
    "            with tqdm(total=len(posts_url)) as pbar2:\n",
    "                    for n, i in enumerate(posts_url, start=1):\n",
    "                        pbar2.update(1)\n",
    "                        pbar2.set_description(f'Posts da {company_}')\n",
    "\n",
    "                        driver.get(i)\n",
    "                        \n",
    "                        info_post()                   \n",
    "                        \n",
    "                        \n",
    "                        driver.get(i)\n",
    "                       \n",
    "                        autor = []\n",
    "                        comentarios = []\n",
    "                        time = []       \n",
    "                        horario_post2 = []\n",
    "                        link_perfil= []\n",
    "                        \n",
    "                        comments2 = []\n",
    "                        autor2 = []\n",
    "                        like_comentario2 = []\n",
    "                        hora2 = []\n",
    "                        comment_id2 = []\n",
    "                        autor_id2 = []\n",
    "                        comment_url2 = []\n",
    "                        n_comments2 = []\n",
    "                        \n",
    "                        scrap_comments()\n",
    "\n",
    "                        while len(driver.find_elements_by_xpath(\"//*[contains(@aria-label,'Load more comments')]\")) == 1:\n",
    "\n",
    "                            page_source = driver.page_source\n",
    "                            profile_bs = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "                            comment_url_aux = []\n",
    "\n",
    "                            elements = driver.find_elements_by_xpath(\"//article/div/div/div/div/a[@href]\")\n",
    "                            for elem in elements:\n",
    "                                urls = elem.get_attribute(\"href\")\n",
    "                                if \"p\" in urls.split(\"/\"):\n",
    "                                    comment_url_aux.append(urls)\n",
    "\n",
    "                            if comment_url_aux == []:\n",
    "                                break\n",
    "\n",
    "                            driver.get(comment_url_aux)\n",
    "\n",
    "                            scrap_comments()\n",
    "\n",
    "                        if len(comments2) == 0:\n",
    "                            comments2, like_comentario2, autor2, hora2,like_comentario2 = [\"NaN\"], [\"NaN\"], [\"NaN\"], [\"NaN\"], [\"NaN\"]\n",
    "\n",
    "\n",
    "                        comment_comment = comment_url2\n",
    "                        if len(comment_url2) > 0:\n",
    "                            for comment_count, aux in enumerate(comment_comment,start=0):\n",
    "                                comment_url2 = []\n",
    "                                driver.get(comment_comment[comment_count])\n",
    "                                 scrap_comments()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        post_data['Tempo_recolha'] = np.concatenate((post_data['Tempo_recolha'], np.tile(datetime.now(), len(comments2))))\n",
    "                        post_data['Categoria'] = np.concatenate((post_data['Categoria'], np.tile(ig['Categoria'][company], len(comments2))))\n",
    "                        post_data['Empresa'] = np.concatenate((post_data['Empresa'], np.tile(ig['Empresa'][company], len(comments2))))\n",
    "                        post_data['post_author_url'] = np.concatenate((post_data['post_author_url'], np.tile(ig['posts'][company], len(comments2))))\n",
    "                        post_data['n'] = np.concatenate((post_data['n'], np.tile(n, len(comments2))))\n",
    "                        post_data['URL_Post'] = np.concatenate((post_data['URL_Post'], np.tile(i, len(comments2))))\n",
    "                        post_data['Texto_Post'] = np.concatenate((post_data['Texto_Post'], np.tile(texto_post, len(comments2))))\n",
    "                        post_data['Data_Post'] = np.concatenate((post_data['Data_Post'], np.tile(data_post_real, len(comments2))))\n",
    "                  #      post_data['Partilhas'] = np.concatenate((post_data['Partilhas'], np.tile(partilhas, len(comments2))))\n",
    "                        #post_data['Autor_Post_ID'] = np.concatenate((post_data['Autor_Post_ID'], np.tile(autor_post_id, len(comments2))))\n",
    "                    #    post_data['Tipo_post_video'] = np.concatenate((post_data['Tipo_post_video'], np.tile(tipo_post_video, len(comments2))))\n",
    "                   #     post_data['Tipo_post_foto'] = np.concatenate((post_data['Tipo_post_foto'], np.tile(tipo_post_foto, len(comments2))))\n",
    "                    #    post_data['Tipo_post_evento'] = np.concatenate((post_data['Tipo_post_evento'], np.tile(tipo_post_evento, len(comments2))))\n",
    "                    #    post_data['Tipo_post_link'] = np.concatenate((post_data['Tipo_post_link'], np.tile(tipo_post_link, len(comments2))))\n",
    "\n",
    "                        size_ = len(post_data['URL_Post'])\n",
    "\n",
    "                        post_data['Likes_Comentario'] = post_data['Likes_Comentario'] + like_comentario2\n",
    "                        post_data['Autor'] = post_data['Autor'] + autor2\n",
    "                     #   post_data['Autor_id'] = post_data['Autor_id'] + autor_id2\n",
    "                        post_data['Comentario'] = post_data['Comentario'] + comments2\n",
    "                     #   post_data['Comentario_id'] = post_data['Comentario_id'] + comment_id2\n",
    "                        post_data['Data_Comentario'] = post_data['Data_Comentario'] + hora2\n",
    "                     #   post_data['N_respostas'] = post_data['N_respostas'] + n_comments2\n",
    "\n",
    "#     print(\"\\n--- %s minutes ---\" % ((time() - start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data['n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data2 = {'Data_recolha':post_data['Tempo_recolha'],\n",
    "              'Categoria':post_data['Categoria'],\n",
    "              'Empresa':post_data['Empresa'],\n",
    "              'post_author_url':post_data['post_author_url'],\n",
    "              #'Autor_Post_ID':post_data['Autor_Post_ID'],\n",
    "              'n': post_data['n'],\n",
    "              'URL_Post': post_data['URL_Post'],\n",
    "              'Texto_Post' : post_data['Texto_Post'],\n",
    "              'Data_Post' : post_data['Data_Post'] ,\n",
    "              'Qtd_post_video':post_data['Tipo_post_video'], \n",
    "              #'Qtd_post_foto':post_data['Tipo_post_foto'], \n",
    "              'Likes_Comentario' : post_data['Likes_Comentario'],\n",
    "              'Autor': post_data['Autor'], \n",
    "              'Comentario': post_data['Comentario'],\n",
    "              'Data_Comentario': post_data['Data_Comentario'], \n",
    "              'Tempo_Recolha': post_data['Tempo_recolha']\n",
    "             }\n",
    "\n",
    "post_data3 = pd.DataFrame.from_dict(post_data2, orient='index')\n",
    "base = post_data3.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = post_data3.transpose()\n",
    "\n",
    "# sticker = base['Autor'] == base['Comentario']\n",
    "# base.loc[sticker,'Comentario'] = ''\n",
    "\n",
    "# fotos = base.loc[(base.Qtd_post_video==0) & (base.Qtd_post_foto==0) & (base.Qtd_post_evento==0) & (base.Qtd_post_link==0),'URL_Post'].str.contains(pat = 'photo')\n",
    "# base.loc[fotos.index,'Qtd_post_foto'] = 1\n",
    "\n",
    "# videos = base.loc[(base.Qtd_post_video==0) & (base.Qtd_post_foto==0) & (base.Qtd_post_evento==0) & (base.Qtd_post_link==0),'URL_Post'].str.contains(pat = 'video')\n",
    "# base.loc[videos.index,'Qtd_post_video'] = 1\n",
    "\n",
    "# base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.Qtd_post_video.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.Comentario.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.Data_Post.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Bases/ig_teste4.xlsx',\n",
    "                        engine='xlsxwriter',options={'strings_to_urls': False}) #.format(staName2)\n",
    "base.to_excel(writer)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_details = {'profile name': names, 'comment': containerzera, 'time': time_post, 'Hora Post': horario_post*len(time_post), \"likes\": likes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(comment_details)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Ravi = df\n",
    "df_Ravi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = container.find_element_by_class_name('_6lAjh').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            container = c.find_element_by_class_name('C4VMK')\n",
    "                name = container.find_element_by_class_name('_6lAjh').text\n",
    "                content = container.find_element_by_tag_name('span').text\n",
    "                content = content.replace('\\n', ' ').strip().rstrip()\n",
    "                time_of_post = browser.find_element_by_xpath('//a/time').get_attribute(\"datetime\")\n",
    "                comment_details = {'profile name': name, 'comment': content, 'time': time_of_post}\n",
    "                print(comment_details)\n",
    "                time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_comments():\n",
    "\n",
    "    global comments2\n",
    "    global comment_id2\n",
    "    global autor2\n",
    "    global like_comentario2\n",
    "    global hora2\n",
    "    global autor_id2\n",
    "    global n_comments2\n",
    "    #global n_respostas2\n",
    "    global comment_url2\n",
    "    \n",
    "    all_comments = driver.find_elements_by_xpath(\"//div[@data-commentid]\")\n",
    "    autor_comentario = driver.find_elements_by_class_name('_2b05')\n",
    "    likes_comentario = driver.find_elements_by_class_name('_14va')\n",
    "    hora_comentario = driver.find_elements_by_xpath(\"//abbr[@classas]\")\n",
    "    \n",
    "    comments = []\n",
    "    #n_resp_ = []\n",
    "    autor = []\n",
    "    like_comentario = []\n",
    "    hora = []\n",
    "    comment_url = []\n",
    "    n_c = []\n",
    "    \n",
    "    for comment in all_comments:\n",
    "        comments.append(comment.text)\n",
    "    \n",
    "    for autor0 in autor_comentario:\n",
    "        autor.append(autor0.text)\n",
    "\n",
    "    for like_comentario0 in likes_comentario:\n",
    "        like_comentario.append(like_comentario0.text)\n",
    "\n",
    "    for horario in hora_comentario:\n",
    "        hora.append(horario.text)\n",
    "\n",
    "    page_source = driver.page_source\n",
    "    profile_bs = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "    name_pattern = re.compile(r'id=\".+?\"')\n",
    "\n",
    "    comment_id = profile_bs.findAll('div', {'data-sigil': 'comment-body'})\n",
    "    comment_id = name_pattern.findall(str(comment_id))\n",
    "\n",
    "    comment_id = [re.sub(r'\"|id=','', x) for x in comment_id]\n",
    "\n",
    "    name_pattern = re.compile(r'ref=\".+?\"')\n",
    "    #name_pattern = re.compile(r'(?:id=.+?&|<a href=\"\\/.+?\\?fnf|.+?\\?rc)')\n",
    "\n",
    "    autor_id = profile_bs.findAll('div', {'class': '_2b05'})\n",
    "    autor_id = name_pattern.findall(str(autor_id))\n",
    "\n",
    "    autor_id = [re.sub(r'\"|ref=|profile.php\\?id=|\\&.*','', x) for x in autor_id]\n",
    "    autor_id = [re.sub(r'\\?fnf|\\?rc=p|\\/','', x) for x in autor_id]\n",
    "    \n",
    "    if comments==[]:\n",
    "        n_c = ['']\n",
    "    else:\n",
    "        name_pattern = re.compile(r'ayk\".+?respos')\n",
    "        n_comments = profile_bs.findAll('div', {'class': '_2b04'})\n",
    "        for rep in n_comments:\n",
    "            aux = name_pattern.findall(str(rep))\n",
    "            if aux == []:\n",
    "                aux = ['']\n",
    "            n_c = np.concatenate((n_c,aux))\n",
    "        n_c = [re.sub(r'ayk\">|respos|·| ','', x) for x in n_c]\n",
    "\n",
    "    #name_pattern = re.compile(r'ayk\".+?respos')\n",
    "\n",
    "    #n_comments = profile_bs.findAll('div', {'class': '_2b04'})\n",
    "\n",
    "    #for rep in n_comments:\n",
    "    #    aux = name_pattern.findall(str(rep))\n",
    "    #    if aux == []:\n",
    "    #        aux = ['']\n",
    "    #    n_c = np.concatenate((n_c,aux))\n",
    "\n",
    "    #n_c = [re.sub(r'ayk\">|respos|·| ','', x) for x in n_c]\n",
    "\n",
    "    #n_respostas = profile_bs.findAll('span', {'class': '_4ayk'})\n",
    "\n",
    "    for comment_url0 in profile_bs.findAll('a',  href = re.compile('comment')):\n",
    "        comment_url.append(base_url + comment_url0['href'])\n",
    "    \n",
    "    #n_resp += np.concatenate((n_resp, list(np.tile('',len(comments)))))\n",
    "    \n",
    "    comment_url2 += comment_url\n",
    "    #n_respostas2 += n_respostas\n",
    "    n_comments2 += n_c\n",
    "    comments2 += comments\n",
    "    comment_id2 += comment_id\n",
    "    autor2 += autor\n",
    "    like_comentario2 += like_comentario\n",
    "    hora2 += hora\n",
    "    autor_id2 += autor_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instagram_comments():\n",
    "    def __init__(self):\n",
    "         self.browser.get('https://www.instagram.com/'+username+'/?hl=en')\n",
    "        \n",
    "    def get_comments(self, url):\n",
    "        self.browser.get(url)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                self.load_more_comments = self.browser.find_element_by_class_name('glyphsSpriteCircle_add__outline__24__grey_9')\n",
    "                self.action = ActionChains(self.browser)\n",
    "                self.action.move_to_element(self.load_more_comments)\n",
    "                self.load_more_comments.click()\n",
    "                time.sleep(4)\n",
    "                self.body_elem = self.browser.find_element_by_class_name('Mr508')\n",
    "                for _ in range(100):\n",
    "                    self.body_elem.send_keys(Keys.END)\n",
    "                    time.sleep(3)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            time.sleep(5)\n",
    "            self.comment = self.browser.find_elements_by_class_name('gElp9 ')\n",
    "            for c in self.comment:\n",
    "                self.container = c.find_element_by_class_name('C4VMK')\n",
    "                self.name = self.container.find_element_by_class_name('_6lAjh').text\n",
    "                self.content = self.container.find_element_by_tag_name('span').text\n",
    "                self.content = self.content.replace('\\n', ' ').strip().rstrip()\n",
    "                self.time_of_post = self.browser.find_element_by_xpath('//a/time').get_attribute(\"datetime\")\n",
    "                self.comment_details = {'profile name': self.name, 'comment': self.content, 'time': self.time_of_post}\n",
    "                print(self.comment_details)\n",
    "                time.sleep(5)\n",
    "                \n",
    "            return self.comment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Instagram_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Na mão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autor_comentario = driver.find_elements_by_class_name('_6lAjh')\n",
    "autor = []\n",
    "for autor0 in autor_comentario:\n",
    "        autor.append(autor0.text)\n",
    "        \n",
    "autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = driver.find_elements_by_class_name('C4VMK')\n",
    "container\n",
    "containerzaum \n",
    "for i in container:\n",
    "        containerzaum.append(i.text)\n",
    "        \n",
    "containerzaum\n",
    "\n",
    "# coments = [i.split('\\n', 1)[1].split(\"\\n\",1)[0] for i in containerzaum]\n",
    "coments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Facebook\n",
    "all_comments = driver.find_elements_by_class_name(\"_6lAjh\")\n",
    "all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste2= []\n",
    "for i in driver.find_elements_by_class_name(\"_6lAjh\"):\n",
    "    teste2.append(i.text)\n",
    "teste2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can simply use a CSS selector, and then print the text attribute of the span element:\n",
    "teste2= []\n",
    "for contact in driver.find_elements_by_css_selector('.C4VMK span'):\n",
    "    teste2.append(contact.text)\n",
    "teste2\n",
    "#Comentários\n",
    "l1 = teste2[1::2]\n",
    "print(l1)\n",
    "#Autor\n",
    "l2 = teste2[0::2]\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste2= []\n",
    "for i in driver.find_elements_by_xpath(\"//li/div/div/div/span\"):\n",
    "    teste2.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = driver.page_source\n",
    "soup = BeautifulSoup(content)\n",
    "time = []\n",
    "\n",
    "for i in soup.findAll('time'):\n",
    "        if i.has_attr('datetime'):\n",
    "            time.append(i['datetime'])\n",
    "            print(i['datetime'])\n",
    "            \n",
    "time_post = time[1:]\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = driver.find_elements_by_class_name('C4VMK')\n",
    "container\n",
    "containerzaum = []\n",
    "for i in container:\n",
    "    containerzaum.append(i.text)\n",
    "containerzaum = containerzaum[1:]\n",
    "containerzaum \n",
    "\n",
    "containerzera =[]\n",
    "for i in containerzaum:\n",
    "    containerzera.append(i[1:])\n",
    "containerzera    \n",
    "\n",
    "like_comentario = []\n",
    "for cont in containerzera:\n",
    "    like_comentario.append(cont[-12:])\n",
    "print(like_comentario)\n",
    "print(len(like_comentario))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = driver.find_elements_by_class_name('_6lAjh ')\n",
    "links\n",
    "link_perfil= []\n",
    "for i in links:\n",
    "    link_perfil.append(i.find_element_by_css_selector('a').get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMENTÁRIOS\n",
    "teste2= []\n",
    "for i in driver.find_elements_by_xpath(\"//li/div/div/div/span\"):\n",
    "    teste2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pattern = re.compile(r'webelement', flags = re.M)\n",
    "tipo_post_video = len(name_pattern.findall(str(driver.find_element_by_tag_name('video'))))\n",
    "tipo_post_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pattern = re.compile(r'webelement', flags = re.M)\n",
    "tipo_post_photo = len(name_pattern.findall(str(driver.find_element_by_tag_name('img'))))\n",
    "tipo_post_photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo = driver.find_element_by_tag_name('time').get_attribute(\"datetime\")\n",
    "tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listona2\n",
    "listona_zord = list(dict.fromkeys(listona2))\n",
    "post_url = [ x for x in listona_zord if \"https://www.instagram.com/p/\" in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
